{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40046272-e6d7-4691-ada2-41d0c813c242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:04:20.720384Z",
     "iopub.status.busy": "2024-12-05T19:04:20.720054Z",
     "iopub.status.idle": "2024-12-05T19:04:22.864673Z",
     "shell.execute_reply": "2024-12-05T19:04:22.864030Z",
     "shell.execute_reply.started": "2024-12-05T19:04:20.720361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-06 15:15:20--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241206%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241206T201520Z&X-Amz-Expires=300&X-Amz-Signature=0d4360a485b2768b0383ea8474d037ff70a40f0a5752a0dedd28a5c9461bacd8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-12-06 15:15:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241206%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241206T201520Z&X-Amz-Expires=300&X-Amz-Signature=0d4360a485b2768b0383ea8474d037ff70a40f0a5752a0dedd28a5c9461bacd8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 160610502 (153M) [application/octet-stream]\n",
      "Saving to: ‘model_2024_hairstyle.keras’\n",
      "\n",
      "model_2024_hairstyl 100%[===================>] 153.17M  28.7MB/s    in 5.5s    \n",
      "\n",
      "2024-12-06 15:15:26 (27.7 MB/s) - ‘model_2024_hairstyle.keras’ saved [160610502/160610502]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69cc2faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl (239.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.0/398.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36354e6-2a87-4e95-bdb3-532676e7dd94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:04:53.400187Z",
     "iopub.status.busy": "2024-12-05T19:04:53.399827Z",
     "iopub.status.idle": "2024-12-05T19:05:07.997650Z",
     "shell.execute_reply": "2024-12-05T19:05:07.996942Z",
     "shell.execute_reply.started": "2024-12-05T19:04:53.400150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13305654032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13305654800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13305655568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13305656336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13305657488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13305658064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1733516207.993355 9368432 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1733516207.993496 9368432 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-06 15:16:47.994759: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9\n",
      "2024-12-06 15:16:47.995170: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-06 15:16:47.995176: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9\n",
      "I0000 00:00:1733516207.999054 9368432 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-12-06 15:16:47.999653: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-06 15:16:48.089413: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/hr/s9cbzdhd7sscw62lc5crt_tw0000gn/T/tmp7xeofk_9\n",
      "2024-12-06 15:16:48.096473: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 101719 microseconds.\n",
      "2024-12-06 15:16:48.120026: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been converted to TF-Lite format and saved as 'model_2024_hairstyle.tflite'.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "keras_model = tf.keras.models.load_model('model_2024_hairstyle.keras')\n",
    "\n",
    "# Create a converter object\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "\n",
    "# (Optional) Optimize the model\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF-Lite model to a file\n",
    "with open('model_2024_hairstyle.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model has been converted to TF-Lite format and saved as 'model_2024_hairstyle.tflite'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf0e48a-44a0-4c48-981a-d40fd6992340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:05:09.719990Z",
     "iopub.status.busy": "2024-12-05T19:05:09.719649Z",
     "iopub.status.idle": "2024-12-05T19:05:09.723991Z",
     "shell.execute_reply": "2024-12-05T19:05:09.723270Z",
     "shell.execute_reply.started": "2024-12-05T19:05:09.719968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the converted TF-Lite model: 76.58 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the size of the TF-Lite model in bytes\n",
    "model_size = os.path.getsize('model_2024_hairstyle.tflite')\n",
    "\n",
    "# Convert to megabytes for readability\n",
    "model_size_mb = model_size / (1024 * 1024)\n",
    "\n",
    "print(f\"Size of the converted TF-Lite model: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acece71-3602-4e42-92bb-deb46aabc22f",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c3f0d9-4f36-4674-bf9f-fbd789eaf40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:09:54.920018Z",
     "iopub.status.busy": "2024-12-05T19:09:54.919426Z",
     "iopub.status.idle": "2024-12-05T19:09:54.996677Z",
     "shell.execute_reply": "2024-12-05T19:09:54.996103Z",
     "shell.execute_reply.started": "2024-12-05T19:09:54.919993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details:\n",
      "{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'shape_signature': array([ -1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "\n",
      "Output Details:\n",
      "{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "\n",
      "Output Index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Path to your TF-Lite model\n",
    "model_path = 'model_2024_hairstyle.tflite'\n",
    "\n",
    "# Load the TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Retrieve input details\n",
    "input_details = interpreter.get_input_details()\n",
    "print(\"Input Details:\")\n",
    "for detail in input_details:\n",
    "    print(detail)\n",
    "\n",
    "# Retrieve output details\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"\\nOutput Details:\")\n",
    "for detail in output_details:\n",
    "    print(detail)\n",
    "\n",
    "# If you specifically need the output index:\n",
    "if output_details:\n",
    "    output_index = output_details[0]['index']\n",
    "    print(f\"\\nOutput Index: {output_index}\")\n",
    "else:\n",
    "    print(\"\\nNo output tensors found in the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f215eb-82bd-48b1-9069-e8c05c362be7",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06551c1e-57ea-4fb8-9a52-3d06c8d27342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:35:01.629826Z",
     "iopub.status.busy": "2024-12-05T19:35:01.629489Z",
     "iopub.status.idle": "2024-12-05T19:35:02.715385Z",
     "shell.execute_reply": "2024-12-05T19:35:02.714696Z",
     "shell.execute_reply.started": "2024-12-05T19:35:01.629805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value in the first pixel, R channel after pre-processing: 0.24\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(url, target_size=(224, 224)):\n",
    "    # Download and resize the image\n",
    "    img = download_image(url)\n",
    "    img = prepare_image(img, target_size)\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    img_array = np.array(img).astype('float32')\n",
    "    \n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Example Usage\n",
    "image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "processed_image = preprocess_image(image_url)\n",
    "\n",
    "# Accessing the first pixel's R channel value\n",
    "first_pixel_r = processed_image[0, 0, 0]\n",
    "print(f\"Value in the first pixel, R channel after pre-processing: {first_pixel_r:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f4135-8145-4811-9ec8-4fd084459f2d",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335f9d88-3278-4b95-91fb-a51823645637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T19:43:17.151013Z",
     "iopub.status.busy": "2024-12-05T19:43:17.150671Z",
     "iopub.status.idle": "2024-12-05T19:43:18.048953Z",
     "shell.execute_reply": "2024-12-05T19:43:18.048267Z",
     "shell.execute_reply.started": "2024-12-05T19:43:17.150990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preprocessing the image...\n",
      "Image downloaded and preprocessed.\n",
      "Loading the TF-Lite model...\n",
      "Model loaded.\n",
      "Expected input shape: [  1 200 200   3]\n",
      "Running inference...\n",
      "Inference completed.\n",
      "Predicted Class: 0\n",
      "Confidence: 0.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    \"\"\"Downloads an image from a URL and returns a PIL Image.\"\"\"\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    \"\"\"Converts image to RGB, resizes it, and returns a PIL Image.\"\"\"\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(img, target_size=(224, 224)):\n",
    "    \"\"\"Downloads, resizes, and normalizes the image.\"\"\"\n",
    "    img = prepare_image(img, target_size)\n",
    "    img_array = np.array(img).astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "def load_tflite_model(model_path):\n",
    "    \"\"\"Loads the TF-Lite model and returns the interpreter.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "def get_output(interpreter, input_data):\n",
    "    \"\"\"Sets the input tensor, invokes the interpreter, and retrieves the output.\"\"\"\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Assuming single input and output\n",
    "    input_index = input_details[0]['index']\n",
    "    output_index = output_details[0]['index']\n",
    "\n",
    "    # Set the tensor to the input data\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "\n",
    "    # Invoke the interpreter\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_index)\n",
    "    return output_data\n",
    "\n",
    "def main():\n",
    "    # URLs and paths\n",
    "    image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "    model_path = \"model_2024_hairstyle.tflite\"\n",
    "\n",
    "    # Step 1: Download and preprocess the image\n",
    "    print(\"Downloading and preprocessing the image...\")\n",
    "    img = download_image(image_url)\n",
    "    processed_image = preprocess_image(img, target_size=(200, 200))  # Ensure target size is 200x200\n",
    "    print(\"Image downloaded and preprocessed.\")\n",
    "\n",
    "    # Step 2: Load the TF-Lite model\n",
    "    print(\"Loading the TF-Lite model...\")\n",
    "    interpreter = load_tflite_model(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "\n",
    "    # Inspect input details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    print(f\"Expected input shape: {input_details[0]['shape']}\")\n",
    "\n",
    "    # Step 3: Get the model's output\n",
    "    print(\"Running inference...\")\n",
    "    output = get_output(interpreter, processed_image)\n",
    "    print(\"Inference completed.\")\n",
    "\n",
    "\n",
    "    # Step 4: Interpret the output\n",
    "    # This step depends on the model's specific output format.\n",
    "    # For demonstration, let's assume it's a classification model with probabilities.\n",
    "\n",
    "    # Example: If the model outputs probabilities for 10 classes\n",
    "    predicted_class = np.argmax(output, axis=1)[0]\n",
    "    confidence = np.max(output, axis=1)[0]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc965465-b955-48f3-a2d9-8d0bbbb5ccfe",
   "metadata": {},
   "source": [
    "### Q 5\n",
    "\n",
    "Prepare the lambda code\n",
    "Now you need to copy all the code into a separate python file. You will need to use this file for the next two questions.\n",
    "\n",
    "Tip: you can test this file locally with ipython or Jupyter Notebook by importing the file and invoking the function from this file.\n",
    "\n",
    "Docker\n",
    "For the next two questions, we'll use a Docker image that we already prepared. This is the Dockerfile that we used for creating the image:\n",
    "\n",
    "FROM public.ecr.aws/lambda/python:3.10\n",
    "\n",
    "COPY model_2024_hairstyle_v2.tflite .\n",
    "\n",
    "RUN pip install numpy==1.23.1\n",
    "Note that it uses Python 3.10. The latest models of TF Lite do not support Python 3.12 yet, so we need to use 3.10. Also, for this part, we will use TensorFlow 2.14.0. We have tested it, and the models created with 2.17 could be served with 2.14.0.\n",
    "\n",
    "For that image, we also needed to use an older version of numpy (1.23.1)\n",
    "\n",
    "The docker image is published to agrigorev/model-2024-hairstyle:v3.\n",
    "\n",
    "A few notes:\n",
    "\n",
    "The image already contains a model and it's not the same model as the one we used for questions 1-4.\n",
    "The wheel for this combination that you'll need to use in your Docker image is https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.14.0-cp310-cp310-linux_x86_64.whl\n",
    "Question 5\n",
    "Download the base image agrigorev/model-2024-hairstyle:v3. You can do it with docker pull.\n",
    "\n",
    "So what's the size of this base image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9624d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3: Pulling from agrigorev/model-2024-hairstyle\n",
      "\n",
      "\u001b[1B68a79b8a: Pulling fs layer \n",
      "\u001b[1B124cce46: Pulling fs layer \n",
      "\u001b[1B8b038848: Pulling fs layer \n",
      "\u001b[1B0580071d: Pulling fs layer \n",
      "\u001b[1B8c0b7487: Pulling fs layer \n",
      "\u001b[1B750232a5: Pulling fs layer \n",
      "\u001b[1Be35356a0: Pulling fs layer \n",
      "\u001b[2Be35356a0: Download complete MB/73.55MB\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2KDigest: sha256:6d0aa19127467401fd439c76e662ceba2bd21a5713f174d4f89b354a26939ea6\n",
      "Status: Downloaded newer image for agrigorev/model-2024-hairstyle:v3\n",
      "docker.io/agrigorev/model-2024-hairstyle:v3\n",
      "\u001b[1m\n",
      "What's next:\u001b[0m\n",
      "    View a summary of image vulnerabilities and recommendations → \u001b[36mdocker scout quickview agrigorev/model-2024-hairstyle:v3\u001b[0m\n",
      "REPOSITORY                       TAG       IMAGE ID       CREATED      SIZE\n",
      "agrigorev/model-2024-hairstyle   v3        6d0aa1912746   3 days ago   1.14GB\n"
     ]
    }
   ],
   "source": [
    "# First pull the image\n",
    "!docker pull agrigorev/model-2024-hairstyle:v3\n",
    "\n",
    "# Then check the image size\n",
    "!docker images agrigorev/model-2024-hairstyle:v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60708274",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Question 6\n",
    "Now let's extend this docker image, install all the required libraries and add the code for lambda.\n",
    "\n",
    "You don't need to include the model in the image. It's already included. The name of the file with the model is model-2024-hairstyle-v2.tflite and it's in the current workdir in the image (see the Dockerfile above for the reference). The provided model requires the same preprocessing for images regarding target size and rescaling the value range than used in homework 8.\n",
    "\n",
    "Now run the container locally.\n",
    "\n",
    "Score this image: https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\n",
    "\n",
    "What's the output from the model?\n",
    "\n",
    "0.229\n",
    "0.429\n",
    "0.629\n",
    "0.829\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b93360b3-dfd6-425f-a4d3-c8f8eb0e6545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)  docker:desktop-linux\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 627B                                       0.0s\n",
      "\u001b[0m => WARN: FromPlatformFlagConstDisallowed: FROM --platform flag should no  0.0s\n",
      " => [internal] load metadata for public.ecr.aws/lambda/python:3.10         0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 627B                                       0.0s\n",
      "\u001b[0m => WARN: FromPlatformFlagConstDisallowed: FROM --platform flag should no  0.0s\n",
      " => [internal] load metadata for public.ecr.aws/lambda/python:3.10         0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (2/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 627B                                       0.0s\n",
      "\u001b[0m => WARN: FromPlatformFlagConstDisallowed: FROM --platform flag should no  0.0s\n",
      "\u001b[34m => [internal] load metadata for public.ecr.aws/lambda/python:3.10         0.4s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (10/10) FINISHED                         docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 627B                                       0.0s\n",
      "\u001b[0m => WARN: FromPlatformFlagConstDisallowed: FROM --platform flag should no  0.0s\n",
      "\u001b[34m => [internal] load metadata for public.ecr.aws/lambda/python:3.10         0.4s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/5] FROM public.ecr.aws/lambda/python:3.10@sha256:6bae8667499142012  0.0s\n",
      "\u001b[0m\u001b[34m => => resolve public.ecr.aws/lambda/python:3.10@sha256:6bae8667499142012  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 77B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/5] RUN pip install numpy==1.23.1                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/5] RUN pip install --no-deps https://github.com/alexeygrigo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/5] RUN pip install Pillow                                    0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/5] COPY lambda_function.py .                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => exporting manifest sha256:2bf0b31d74a83ce53557a4729bd811e46ff35df4  0.0s\n",
      "\u001b[0m\u001b[34m => => exporting config sha256:351bbb63f9df63aaf587d3556ebc247e8ad3fa88e9  0.0s\n",
      "\u001b[0m\u001b[34m => => exporting attestation manifest sha256:162f6dab61fb268b2e956035cb1c  0.0s\n",
      "\u001b[0m\u001b[34m => => exporting manifest list sha256:39a9e76ade108722444e729cc9cea578d00  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/hairstyle-lambda:latest                 0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      " \u001b[33m1 warning found (use docker --debug to expand):\n",
      "\u001b[0m - FromPlatformFlagConstDisallowed: FROM --platform flag should not use constant value \"linux/amd64\" (line 1)\n",
      "\u001b[1m\n",
      "What's next:\u001b[0m\n",
      "    View a summary of image vulnerabilities and recommendations → \u001b[36mdocker scout quickview \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!docker build --platform=linux/amd64 -t hairstyle-lambda .\n",
    "\n",
    "#!docker run --platform=linux/amd64 -it --rm hairstyle-lambda python -c \"import lambda_function; event = {'url': 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'}; print(lambda_function.lambda_handler(event, None))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233a2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07 Dec 2024 03:19:19,439 [INFO] (rapid) exec '/var/runtime/bootstrap' (cwd=/var/task, handler=)\n",
      "07 Dec 2024 03:20:33,182 [INFO] (rapid) INIT START(type: on-demand, phase: init)\n",
      "START RequestId: afa0a5f0-8208-4d12-b307-80bc0f95ecd5 Version: $LATEST\n",
      "07 Dec 2024 03:20:33,185 [INFO] (rapid) The extension's directory \"/opt/extensions\" does not exist, assuming no extensions to be loaded.\n",
      "07 Dec 2024 03:20:33,187 [INFO] (rapid) Starting runtime without AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN , Expected?: false\n",
      "07 Dec 2024 03:20:33,712 [INFO] (rapid) INIT RTDONE(status: success)\n",
      "07 Dec 2024 03:20:33,712 [INFO] (rapid) INIT REPORT(durationMs: 531.900000)\n",
      "07 Dec 2024 03:20:33,713 [INFO] (rapid) INVOKE START(requestId: 5a356d55-60cb-4a08-83f4-0050d621e227)\n",
      "Downloading image...\n",
      "Preprocessing image...\n",
      "Loading model and making prediction...\n",
      "    self._interpreter = _interpreter_wrapper.CreateWrapperFromFile(preter.py\", line 464, in __init__, in rare cases, a Lambda runtime update can cause unexpected function behavior. For functions using managed runtimes, runtime updates can be triggered by a function change, or can be applied automatically. To determine if the runtime has been updated, check the runtime version in the INIT_START log entry. If this error correlates with a change in the runtime version, you may be able to mitigate this error by temporarily rolling back to the previous runtime version. For more information, see https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html\n",
      "07 Dec 2024 03:20:35,263 [INFO] (rapid) INVOKE RTDONE(status: success, produced bytes: 0, duration: 1549.816000ms)\n",
      "END RequestId: 5a356d55-60cb-4a08-83f4-0050d621e227\n",
      "REPORT RequestId: 5a356d55-60cb-4a08-83f4-0050d621e227\tInit Duration: 1.71 ms\tDuration: 2083.18 ms\tBilled Duration: 2084 ms\tMemory Size: 3008 MB\tMax Memory Used: 3008 MB\t\n"
     ]
    }
   ],
   "source": [
    "!docker run --platform=linux/amd64 -p 8080:8080 hairstyle-lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb099186",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
