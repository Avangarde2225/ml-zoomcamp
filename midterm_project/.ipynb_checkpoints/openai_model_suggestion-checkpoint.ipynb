{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee28d72-3564-4899-81a8-7575c1bc4940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression\n",
      "Error during model fitting: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Model: LogisticRegression | Metrics: None\n",
      "Training model: DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import ast\n",
    "import re\n",
    "import sklearn\n",
    "from openai import OpenAI\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model_mapping = {\n",
    "    \"LogisticRegression\": LogisticRegression,\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"DecisionTreeRegressor\":DecisionTreeRegressor,\n",
    "    \"LinearRegression\":LinearRegression\n",
    "}\n",
    "\n",
    "def load_config(config_path='/Users/serdarc/Desktop/ml-zoomcamp/midterm_project/config.yaml'):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    return pd.read_csv(dataset_path)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    label_encoders = {}\n",
    "    for column in df.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "def call_llm(prompt, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in machine learning and able to evaluate the model well.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices.message.content.strip()\n",
    "\n",
    "def clean_hyperparameter_suggestion(suggestion):\n",
    "    pattern = r'\\{.*?\\}'\n",
    "    match = re.search(pattern, suggestion, re.DOTALL)\n",
    "    if match:\n",
    "        cleaned_suggestion = match.group(0)\n",
    "        return cleaned_suggestion\n",
    "    else:\n",
    "        print(\"Could not find a dictionary in the hyperparameter suggestion.\")\n",
    "        return None\n",
    "\n",
    "def extract_model_name(llm_response, available_models):\n",
    "    for model in available_models:\n",
    "        pattern = r'\\b' + re.escape(model) + r'\\b'\n",
    "        if re.search(pattern, llm_response, re.IGNORECASE):\n",
    "            return model\n",
    "    return None\n",
    "\n",
    "def validate_hyperparameters(model_class, hyperparameters):\n",
    "    valid_params = model_class().get_params()\n",
    "    invalid_params = []\n",
    "    for param, value in hyperparameters.items():\n",
    "        if param not in valid_params:\n",
    "            invalid_params.append(param)\n",
    "        else:\n",
    "            if param == 'max_features' and value == 'auto':\n",
    "                print(f\"Invalid value for parameter '{param}': '{value}'\")\n",
    "                invalid_params.append(param)\n",
    "    if invalid_params:\n",
    "        print(f\"Invalid hyperparameters for {model_class.__name__}: {invalid_params}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def correct_hyperparameters(hyperparameters, model_name):\n",
    "    corrected = False\n",
    "    if model_name == \"RandomForestClassifier\":\n",
    "        if 'max_features' in hyperparameters and hyperparameters['max_features'] == 'auto':\n",
    "            print(\"Correcting 'max_features' from 'auto' to 'sqrt' for RandomForestClassifier.\")\n",
    "            hyperparameters['max_features'] = 'sqrt'\n",
    "            corrected = True\n",
    "    return hyperparameters, corrected\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, model_name, hyperparameters=None):\n",
    "    if model_name not in model_mapping:\n",
    "        print(f\"Valid model names are: {list(model_mapping.keys())}\")\n",
    "        return None, None\n",
    "    model_class = model_mapping.get(model_name)\n",
    "    try:\n",
    "        if hyperparameters:\n",
    "            hyperparameters, corrected = correct_hyperparameters(hyperparameters, model_name)\n",
    "            if not validate_hyperparameters(model_class, hyperparameters):\n",
    "                return None, None\n",
    "            model = model_class(**hyperparameters)\n",
    "        else:\n",
    "            model = model_class()\n",
    "    except Exception as e:\n",
    "        print(f\"Error instantiating model with hyperparameters: {e}\")\n",
    "        return None, None\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model fitting: {e}\")\n",
    "        return None, None\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    return metrics, model\n",
    "\n",
    "def run_llm_based_model_selection_experiment(df, config):\n",
    "    #Model Training\n",
    "    X = df.drop(\"PASSENGERS\", axis=1)\n",
    "    y = df[\"PASSENGERS\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    available_models = config['default_models']\n",
    "    model_performance = {}\n",
    "    for model_name in available_models:\n",
    "        print(f\"Training model: {model_name}\")\n",
    "        metrics, _ = train_and_evaluate(X_train, X_test, y_train, y_test, model_name)\n",
    "        model_performance[model_name] = metrics\n",
    "        print(f\"Model: {model_name} | Metrics: {metrics}\")\n",
    "\n",
    "    #LLM selecting the best model\n",
    "    sklearn_version = sklearn.__version__\n",
    "    prompt = (\n",
    "        f\"I have trained the following models with these metrics: {model_performance}. \"\n",
    "        \"Which model should I select based on the best performance?\"\n",
    "    )\n",
    "    best_model_response = call_llm(prompt, config['llm_api_key'])\n",
    "    print(f\"LLM response for best model selection:\\n{best_model_response}\")\n",
    "    best_model = extract_model_name(best_model_response, available_models)\n",
    "    if not best_model:\n",
    "        print(\"Error: Could not extract a valid model name from LLM response.\")\n",
    "        return\n",
    "    print(f\"LLM selected the best model: {best_model}\")\n",
    "\n",
    "    #Check for hyperparameter tuning\n",
    "    prompt_tuning = (\n",
    "        f\"The selected model is {best_model}. Can you suggest hyperparameters for better performance? \"\n",
    "        \"Please provide them in Python dictionary format, like {'max_depth': 5, 'min_samples_split': 4}. \"\n",
    "        f\"Ensure that all suggested hyperparameters are valid for scikit-learn version {sklearn_version}, \"\n",
    "        \"and avoid using deprecated or invalid values such as 'max_features': 'auto'. \"\n",
    "        \"Don't provide any explanation or return in any other format.\"\n",
    "    )\n",
    "    tuning_suggestion = call_llm(prompt_tuning, config['llm_api_key'])\n",
    "    print(f\"Hyperparameter tuning suggestion received:\\n{tuning_suggestion}\")\n",
    "    cleaned_suggestion = clean_hyperparameter_suggestion(tuning_suggestion)\n",
    "    if cleaned_suggestion is None:\n",
    "        suggested_params = None\n",
    "    else:\n",
    "        try:\n",
    "            suggested_params = ast.literal_eval(cleaned_suggestion)\n",
    "            if not isinstance(suggested_params, dict):\n",
    "                print(\"Hyperparameter suggestion is not a valid dictionary.\")\n",
    "                suggested_params = None\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error parsing hyperparameter suggestion: {e}\")\n",
    "            suggested_params = None\n",
    "\n",
    "    #Automatically run hyperparameter tuning if suggested\n",
    "    if suggested_params:\n",
    "        print(f\"Running {best_model} with suggested hyperparameters: {suggested_params}\")\n",
    "        tuned_metrics, _ = train_and_evaluate(\n",
    "            X_train, X_test, y_train, y_test, best_model, hyperparameters=suggested_params\n",
    "        )\n",
    "        print(f\"Metrics after tuning: {tuned_metrics}\")\n",
    "    else:\n",
    "        print(\"No valid hyperparameters were provided for tuning.\")\n",
    "\n",
    "def main():\n",
    "    config = load_config()\n",
    "    df = load_data(config['dataset_path'])\n",
    "    df, _ = preprocess_data(df)\n",
    "    run_llm_based_model_selection_experiment(df, config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
